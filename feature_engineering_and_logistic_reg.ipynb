{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain in Australia - Predict next-day rain in Australia using logistic regression (Yes / no)\n",
    "### please download the data from: https://rdrr.io/cran/rattle.data/man/weatherAUS.html and place it inside the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see what data available in our data directory\n",
    "for direname, _ , filenames in os.walk(\"data\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(direname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = \"data/weatherAUS.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape\n",
    "print(df.shape)\n",
    "# column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of variables\n",
    "# categrical variables\n",
    "print(df[\"WindGustDir\"].dtype)\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "print(\"There are {} categorical variables\\n\".format(len(categorical)))\n",
    "print(\"The categorical variables are: \", categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RISK_MM variable\n",
    "df.drop(['RISK_MM'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the target variable has any na/null values\n",
    "print(df.shape)\n",
    "df = df[df['RainTomorrow'].notna()]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore categorical variables\n",
    "df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing variables\n",
    "print(df[categorical].isnull().sum())\n",
    "print(\"********\\nPercentages of missing values\\n********\")\n",
    "print(100 * df[categorical].isnull().sum() / df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which of these variables has missing values?\n",
    "cat_with_missing = [var for var in categorical if df[var].isnull().sum() > 0]\n",
    "print(df[cat_with_missing].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency counts of the categorical variables\n",
    "for var in categorical:\n",
    "    print(df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentages in each of the categorical variables\n",
    "for var in categorical:\n",
    "    print(df[var].value_counts() / df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cardinality (number of unique labels) of each catogrical variable\n",
    "for var in categorical:\n",
    "    us = df[var].unique()\n",
    "    print(var, ' contains ', len(us), ' labels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the date variable in to year-month-day\n",
    "df['Date'] = pd.to_datetime(df['Date']) # parse from strings to date time\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "# drop the date column\n",
    "df.drop('Date', axis=1, inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to explore each of the categorical variables\n",
    "def explore_categorical(df, var):\n",
    "    # check if the variable has any missing values\n",
    "    print('********** missing values **********')\n",
    "    print(df[var].isnull().sum())\n",
    "    print('********** Labels **********')\n",
    "    # check unique lables in variable\n",
    "    print(df[var].unique())\n",
    "    print('********** frequency **********')\n",
    "    # check frequency of each variable\n",
    "    print(df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(df, 'Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(df, 'WindGustDir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(df, 'WindDir9am') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(df, 'WindDir3pm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(df, 'RainToday') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(df, 'RainTomorrow') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding using pandas\n",
    "pd.get_dummies(df['RainTomorrow'], drop_first=False, dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find numerical variables\n",
    "numericals = [var for var in df.columns if df[var].dtype != 'O']\n",
    "print('There are {} numerical variables\\n'.format(len(numericals)))\n",
    "print('The numerical variables are :', numericals)\n",
    "df[numericals].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore problems within numerical variables\n",
    "# check missing values in numerical variables\n",
    "df[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view summary statistics in numerical variables\n",
    "print(round(df[numericals].describe()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw boxplots to visualise outliers in these variables\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2,2,1)\n",
    "fig = df.boxplot(column= 'Rainfall')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Rainfall')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "fig = df.boxplot(column= 'Evaporation')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Evaporation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "fig = df.boxplot(column= 'WindSpeed9am')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('WindSpeed9am')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "fig = df.boxplot(column= 'WindSpeed3pm')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('WindSpeed3pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use seaborn library to plot elegant ones\n",
    "df_custom = df[['Rainfall', 'Evaporation', 'WindSpeed9am', 'WindSpeed3pm']]\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = sns.boxplot(data=df_custom, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram to check distribution\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "fig = df['Rainfall'].hist(bins=10)\n",
    "fig.set_xlabel('Rainfall')\n",
    "fig.set_ylabel('RainTomorrow')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "fig = df.Evaporation.hist(bins=10)\n",
    "fig.set_xlabel('Evaporation')\n",
    "fig.set_ylabel('RainTomorrow')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "fig = df.WindSpeed9am.hist(bins=10)\n",
    "fig.set_xlabel('WindSpeed9am')\n",
    "fig.set_ylabel('RainTomorrow')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "fig = df.WindSpeed3pm.hist(bins=10)\n",
    "fig.set_xlabel('WindSpeed3pm')\n",
    "fig.set_ylabel('RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find aoutliers in these variables\n",
    "def find_outliers(variable, factor= 3, print_summary=True):\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "    Lower_boundary = df[variable].quantile(0.25) - (IQR * factor)\n",
    "    Upper_boundary = df[variable].quantile(0.75) + (IQR * factor)\n",
    "    \n",
    "    outliers= []\n",
    "    for index, val in enumerate(df[variable]):\n",
    "        if val < Lower_boundary or val > Upper_boundary:\n",
    "            outliers.append(index)\n",
    "    \n",
    "    \n",
    "    if(print_summary):\n",
    "        print('{variable} outliers are values < {lowerboundary} or > {upperboundary}'.format(variable= variable, lowerboundary=Lower_boundary, upperboundary=Upper_boundary))\n",
    "    return Lower_boundary, Upper_boundary, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = find_outliers('Rainfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = find_outliers('Evaporation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = find_outliers('WindSpeed9am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = find_outliers('WindSpeed3pm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare source and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['RainTomorrow'], axis=1)\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into separate training and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display categorical variables\n",
    "categorical = [var for var in X_train.columns if X_train[var].dtypes == 'O']\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display numerical variables\n",
    "numericals = [var for var in X_train.columns if X_train[var].dtypes != 'O']\n",
    "numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering missing values in numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display missing values\n",
    "X_train[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I could do the same for the text data\n",
    "X_test[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing values in each variable\n",
    "round(X_train[numericals].isnull().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values with the median values -- median is robust with the outliers\n",
    "for df_temp in [X_train, X_test]:\n",
    "    for col in numericals:\n",
    "        col_median = X_train[col].median() # get it only from training\n",
    "        df_temp[col].fillna(col_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again missing values in numerical variables in X_train\n",
    "X_train[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in numerical variables in X_test\n",
    "X_test[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering missing values in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(X_train[categorical].isnull().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing categorical variables with most frequent value (i.e., mode)\n",
    "for df_temp in [X_train, X_test]:\n",
    "    for col in categorical:\n",
    "        col_mode = X_train[col].mode()[0] # get it only from training\n",
    "        df_temp[col].fillna(col_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in categorical variables in X_train\n",
    "X_train[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in categorical variables in X_test\n",
    "X_test[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering outliers in numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the outliers with some predefined the maximum value for each variable\n",
    "def max_value(df_temp, variable, top):\n",
    "    return np.where(df_temp[variable]>top, top, df_temp[variable])\n",
    "\n",
    "cols_with_outliers = {'Rainfall': 3.2, \n",
    "                      'Evaporation': 21.8, \n",
    "                      'WindSpeed9am': 55, \n",
    "                      'WindSpeed3pm': 57\n",
    "                     }\n",
    "for df_temp in [X_train, X_test]:\n",
    "    for col in cols_with_outliers:\n",
    "        df_temp[col] = max_value(df_temp, col, cols_with_outliers[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.Rainfall.max(), X_test.Rainfall.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.Evaporation.max(), X_test.Evaporation.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.WindSpeed9am.max(), X_test.WindSpeed9am.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.WindSpeed3pm.max(), X_test.WindSpeed3pm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use seaborn library to plot elegant ones\n",
    "df_custom = X_train[['Rainfall', 'Evaporation', 'WindSpeed9am', 'WindSpeed3pm']]\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = sns.boxplot(data=df_custom, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RainToday is binary, we can use the BinaryEncoder to create a one-hot encoder for it\n",
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['RainToday'])\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create training set\n",
    "X_train = pd.concat([X_train[numericals], X_train[['RainToday_0', 'RainToday_1']],\n",
    "                     pd.get_dummies(X_train.Location), \n",
    "                     pd.get_dummies(X_train.WindGustDir),\n",
    "                     pd.get_dummies(X_train.WindDir9am),\n",
    "                     pd.get_dummies(X_train.WindDir3pm)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create test set\n",
    "X_test = pd.concat([X_test[numericals], X_test[['RainToday_0', 'RainToday_1']],\n",
    "                     pd.get_dummies(X_test.Location), \n",
    "                     pd.get_dummies(X_test.WindGustDir),\n",
    "                     pd.get_dummies(X_test.WindDir9am),\n",
    "                     pd.get_dummies(X_test.WindDir3pm)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature scaling or standardiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first keep the column name to get the DF back\n",
    "cols = X_train.columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# get the DFs back\n",
    "X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "X_test = pd.DataFrame(X_test, columns=[cols])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positives (Actual Positive:1 and Predict Positive:1) - 20892\n",
    "# True Negatives (Actual Negative:0 and Predict Negative:0) - 3285\n",
    "# False Positives (Actual Negative:0 but Predict Positive:1) - 1175 (Type I error)\n",
    "# False Negatives (Actual Positive:1 but Predict Negative:0) - 3087 (Type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_normalised = cm.astype('float32') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "cm_matrix = pd.DataFrame(data=cm_normalised, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='.2f', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what are the other metrics that you could extract and interpret?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
